# 3. Neural Network

인공 신경망의 개념인 Neural Network에 대해 알아보는 시간을 갖겠습니다.

1.1 인공 신경망 알고리즘의 개념  
--

알파고나 머신 러닝에서 많이 언급되는 알고리즘은 단연 딥 러닝입니다. 딥 러닝은 머신 러닝의 한 종류로 인공 신경망 알고리즘의 새로운 이름입니다.

인공 신경망은 __사람의 두뇌가 여러 개의 뉴런으로 연결되어 복잡한 연산을 수행한다.__ 는 개념에서 영감을 받아, 머신러닝의 연산을 여러 개의 간단한 노드를 뉴런처럼 __상호 연결하여 복잡한 연산을 하겠다.__ 는 아이디어입니다.
![image](https://t1.daumcdn.net/cfile/tistory/220B383B583AC4C61B)
> __그림__: 뉴런의 구조

1.2 단순화한 뉴런
--

뉴런은 돌기를 통해 여러 신경 자극을 입력 받고, 이를 세포체가 인지하여 신호로 변환해줍니다.   
즉, 신경 자극을 입력 받아 __신호__ 라는 결과로 변환해주는 과정을 거칩니다.
![image](https://t1.daumcdn.net/cfile/tistory/2646C93B583AC4C63B)
> __그림__: 단순화한 뉴런

1.3 컴퓨터로 형상화한 뉴런의 구조
--

뉴런의 돌기처럼 외부에서 입력값 X1, X2, X3를 읽습니다. 이 입력값들은 돌기를 거치면서 인식되어 각각 W1 * X1, W2 * X2, W3 * X3  변환이 되어 세포체에 도착하여 여러 돌기에서 들어온 값은 (W1 * X1, W2 * X2, W3 * X3)+b 값으로 취합됩니다. 

이렇게 취합된 값은, 세포체내에서 인지를 위해 어떤 함수f(x)를 거치게 되고, 이 값이 일정 값을 넘게 되면 Y에 1이라는 신호를 주고, 일정값을 넘지 않으면 0이라는 값을 줍니다.
![image](https://t1.daumcdn.net/cfile/tistory/237AF13B583AC4C710)
> __그림__: 컴퓨터로 형상화한 뉴런의 구조

1.4 Perceptron
--

퍼셉트론은 다수의 신호(Input)을 입력받아 하나의 신호(Output)을 출력합니다. 이는 뉴런이 전기신호를 내보내 정보를 전달하는 것과 비슷하죠. 그리고 뉴런의 수상돌기나 축색돌기처럼 신호를 전달하는 역할을 퍼셉트론에서는 __weight__ 가 그 역할을 합니다. 

__가중치__ 라고 부르는 이 weight는 각각의 입력 신호에 부여되어 입력 신호와의 계산을 하고 신호의 총 합이 정해진 임계값(θ; theta, 세타)을 넘었을 때, 1을 출력하고 (이를 뉴런의 활성화(actication)으로 표현) 1을 넘지 못하면 0또는 -1을 출력합니다. 

각 입력신호에는 고유한 weight가 부여되며 weight가 클수록 해당 신호가 중요하다고 볼 수 있습니다. 

![image](https://image.slidesharecdn.com/lecture29-convolutionalneuralnetworks-visionspring2015-150504114140-conversion-gate02/95/lecture-29-convolutional-neural-networks-computer-vision-spring2015-9-638.jpg?cb=1430740006)
> __그림__: Neuron 과 Perceptron의 구조

퍼셉트론의 출력 값은 1 또는 0이기 떄문에 선형 분류(linear classifier) 모형이라고도 볼 수 있습니다. 보통 실수형의  입력 벡터를 받아 이들의 선형조합을 계산하는 것이며 벡터의 내적과도 유사합니다. 

![image](http://www.saedsayad.com/images/Perceptron_3.png) 
> __그림__: 퍼셉트론의 구성

1.5 퍼셉트론의 학습 방법
--

퍼셉트론의 학습 방법
1. 임의로 설정된 weight로 시작
2. 학습 데이터를 퍼셉트론 모형에 입력
3. 잘못되었을 때 weight 값을 개선

![image](https://image.slidesharecdn.com/machine-learning-120930145310-phpapp01/95/machine-learning-with-applications-in-categorization-popularity-and-sequence-labeling-75-638.jpg?cb=1354541953)
> __그림__: 퍼셉트론 알고리즘의 정의

퍼셉트론은 모든 학습 데이터를 정확히 분류시킬 때까지 학습이 진행되기때문에 학습 데이터가 선형적으로 분리될 수 있을 때 적합한 알고리즘입니다.

선형분류는 선으로 분류하는 것을 의미합니다. 
아래의 그림을 보면, 학습이 반복될수록 선의 기울기가 달라지는데, 이는 학습을 진행하면서 weight가 계속 조정되는 것을 나타냅니다. 

![image](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Perceptron_example.svg/500px-Perceptron_example.svg.png)
> __그림__: 퍼셉트론의 학습 과정

1.6 퍼셉트론의 한계, XOR
--

퍼셉트론은 인공지능 분야에 센세이션을 불러왔으나, 한계점이 있었습니다.  
아래의 그림처럼 직선 하나로 AND, OR 문제는 해결이 가능하지만 직선 하나로 XOR 문제를 풀 수가 없었기 때문입니다.

![image](http://ecee.colorado.edu/~ecen4831/lectures/xor2.gif)
> __그림__: 퍼셉트론으로 OR, AND, XOR을 표현한 그림

1.7 Multi-Layer Perceptron
--

퍼셉트론의 XOR 문제를 해결하기 위해 다층 퍼셉트론(Multi-layer Perceptron)이 고안되었습니다. 다층 퍼셉트론은 입력층과 출력층 사이에 하나 이상의 중간층을 두어 비선형적으로 분리되는 데이터에 대해서도 학습이 가능하도록 하는 방식이었습니다. 

![image](http://mblogthumb3.phinf.naver.net/MjAxODAzMjhfMjA4/MDAxNTIyMTk3ODQyMzk2.denKdPpRR2e8NQKv93P2B82uaMX1ygVWlyiP29gTnOAg.-Wr1aOLP56BVNZyQ4Yf3R_19k2F5BE25-di6H955my0g.JPEG.msnayana/MLP.jpg?type=w800)
> __그림__: 다층 퍼셉트론(MLP)의 구조

입력층과 출력층 사이에 존재하는 중간층을 숨어 있는 층이라 하여 __은닉층__ 이라 부릅니다. 입력층과 출력층 사이에 여러개의 은닉층이 있는 인공 신경망을 심층 신경망(deep neural network)이라 부르며, 심층 신경망을 학습하기 위해 고안된 특별한 알고리즘들을 __딥 러닝(deep learning)__ 이라 부릅니다. 

다층 퍼셉트론에서는 입력층에서 전달되는 값이 은닉층의 모든 노드로 전달되며 은닉층의 모든 노드의 출력값 역시 출력층의 모든 노드로 전달됩니다. 이런 형식으로 값이 전달되는 것을 __순전파(feedforward)__ 라 합니다. 입력층과 은닉층에 있는 한개의 노드만 볼 때, 하나의 단층 퍼셉트론으로 생각할 수 있습니다. 따라서, 은닉층에 있는 각각의 노드는 퍼셉트론의 __활성 함수__ 라고 볼 수 있습니다. 

1.8 Stride
--
필터를 원본 이미지에 적용할 때 필터를 적용하는 간격을 Stride라고 하고, 필터를 적용해서 얻어낸 결과를 __Feature map__ 또는 __activation map__ 이라고 한다. 

![image](https://t1.daumcdn.net/cfile/tistory/210B0A39583EDBBB05)

> __그림__: Stride의 이해